{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69467551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c413a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('casper15.json',encoding='utf-8') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8acbf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Обучение аффективным событиям с минимальным контролем с использованием дискурсивных отношений',\n",
       " 'ПО-ЭМО: концептуализация, аннотация и моделирование эстетических эмоций в немецкой и английской поэзии',\n",
       " 'Идентичность сообщества и вовлечение пользователей в среду, состоящую из нескольких сообществ',\n",
       " 'Структурирование клинического текста на основе ответов на вопросы с использованием предварительно обученной языковой модели',\n",
       " 'Прогресс и компромиссы в моделях нейронного языка',\n",
       " 'Оставайтесь в курсе темы: создание поддельных обзоров ресторанов с учетом контекста',\n",
       " 'Генерация карт значимости для автоматического суммирования текста',\n",
       " 'Вероятностное смягчение смещения при встраивании слов',\n",
       " 'Массивные и тщательно подобранные встраивания слов для языков с ограниченными ресурсами. Дело Йоруба и Тви',\n",
       " 'Есть ли гендерная предвзятость и стереотипы в португальских словах?',\n",
       " 'Данные цитирования чешских высших судов',\n",
       " 'LAXARY: надежная и объяснимая модель анализа Twitter для оценки посттравматического стрессового расстройства',\n",
       " 'Комплексное распознавание именованных объектов на CORD-19 с дистанционным или слабым контролем',\n",
       " 'UniSent: универсальная адаптируемая лексика Sentiment Lexica для более чем 1000 языков',\n",
       " 'Устранение неоднозначности смысла слова для 158 языков с использованием только встраивания слов',\n",
       " 'Идентификация разговорного языка с использованием ConvNets']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['titles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66583917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Распознавание аффективных событий, которые вызывают положительные или отрицательные эмоции, имеет широкий спектр приложений для обработки естественного языка, но остается сложной проблемой, главным образом потому, что полярность события не обязательно предсказуема по составляющим его словам. В этой статье мы предлагаем пропагандировать аффективную полярность с помощью дискурсивных отношений. Наш метод прост и требует лишь очень небольшого исходного словаря и большого необработанного корпуса. Наши эксперименты с использованием японских данных показывают, что наш метод эффективно изучает аффективные события без маркировки данных вручную. Это также улучшает результаты контролируемого обучения, когда помеченные данные малы.',\n",
       " 'Большинство подходов к анализу эмоций в социальных сетях, литературе, новостях и других областях сосредоточены исключительно на базовых категориях эмоций, определенных Экманом или Плутчиком. Однако искусство (например, литература) позволяет проявлять более широкий спектр более сложных и тонких эмоций, которые, как было показано, также включают смешанные эмоциональные реакции. Мы рассматриваем эмоции такими, какие они вызывают у читателя, а не то, что выражено в тексте или задумано автором. Таким образом, мы концептуализируем набор эстетических эмоций, которые предсказывают эстетическое восприятие читателя, и позволяем аннотировать несколько ярлыков в строке, чтобы уловить смешанные эмоции в контексте. Мы оцениваем этот новый сеттинг в эксперименте с аннотациями как с тщательно подготовленными экспертами, так и с помощью краудсорсинга. Наша аннотация с экспертами приводит к приемлемому соглашению каппа = 0,70, что приводит к созданию согласованного набора данных для будущего крупномасштабного анализа. Наконец, мы проводим первые эксперименты по классификации эмоций на основе BERT, показывая, что идентифицировать эстетические эмоции по нашим данным сложно: до 0,52 F1-микро в немецкой подгруппе. Данные и ресурсы доступны по адресу https://github.com/tnhaider/poetry-emotion.',\n",
       " 'Идентичность сообщества определяет и формирует его внутреннюю динамику. Наше нынешнее понимание этого взаимодействия в основном ограничивается взглядами, полученными в результате изолированных исследований отдельных сообществ. В этой работе мы обеспечиваем систематическое исследование природы этих отношений в самых разных онлайн-сообществах. С этой целью мы вводим количественную, основанную на языке типологию, отражающую два ключевых аспекта идентичности сообщества: насколько оно самобытно и насколько оно динамично во времени. Сопоставляя почти 300 сообществ Reddit с ландшафтом, созданным этой типологией, мы выявляем закономерности в том, как модели взаимодействия пользователей варьируются в зависимости от характеристик сообщества. Наши результаты показывают, что способ взаимодействия новых и существующих пользователей с сообществом сильно и систематически зависит от природы коллективной идентичности, которую оно воспитывает, и это имеет большое значение для тех, кто поддерживает сообщество. Например, сообщества с отличительной и очень динамичной идентичностью с большей вероятностью сохранят своих пользователей. Однако такие нишевые сообщества также демонстрируют гораздо больший разрыв в культуре между существующими пользователями и новичками, что потенциально препятствует интеграции последних. В более общем плане наша методология выявляет различия в том, как различные социальные явления проявляются в разных сообществах, и показывает, что структурирование многосообществного ландшафта может привести к лучшему пониманию систематического характера этого разнообразия.',\n",
       " 'Структурирование клинического текста является важнейшей и фундаментальной задачей клинических исследований. Традиционные методы, такие как сквозные модели для конкретных задач и модели конвейеров, обычно страдают от недостатка набора данных и распространения ошибок. В этой статье мы представляем задачу структурирования клинического текста (QA-CTS) на основе ответов на вопросы, позволяющую унифицировать различные конкретные задачи и сделать набор данных доступным для совместного использования. Для задачи QA-CTS также предлагается новая модель, целью которой является внедрение специфичных для предметной области функций (например, информации о клиническом названии объекта) в предварительно обученную языковую модель. Экспериментальные результаты отчетов о патологиях в Китае, собранных в больнице Жуйцзин, показывают, что представленная нами задача QA-CTS очень эффективна для улучшения производительности при выполнении конкретных задач. Предложенная нами модель также выгодно конкурирует с сильными базовыми моделями в конкретных задачах.',\n",
       " 'В последние годы мы стали свидетелями резкого перехода к методам, основанным на нейронных сетях, для решения различных задач НЛП. Несомненно, модели нейронного языка (NLM) значительно уменьшили недоумение. Однако этот прогресс приводит к существенному снижению производительности с точки зрения задержки вывода и энергопотребления, что особенно вызывает беспокойство при развертывании на мобильных устройствах. Эта статья, в которой исследуется соотношение качества и производительности различных методов языкового моделирования, является, насколько нам известно, первым, в котором сделано это наблюдение. Мы сравниваем современные NLM с «классическими» LM Кнезера-Нея (KN) с точки зрения энергопотребления, задержки, запутанности и точности прогнозирования, используя два стандартных теста. На Raspberry Pi мы обнаружили, что порядки увеличения задержки и энергопотребления соответствуют меньшим изменениям в недоумении, в то время как на настольном компьютере разница гораздо менее выражена.',\n",
       " 'Автоматически генерируемые фальшивые обзоры ресторанов представляют угрозу для систем онлайн-обзоров. Недавние исследования показали, что пользователям трудно обнаружить сгенерированные компьютером фальшивые отзывы, скрывающиеся среди реальных отзывов о ресторанах. Используемый в данной работе метод (char-LSTM) имеет один недостаток: ему трудно оставаться в контексте, т.е. когда он генерирует обзор для конкретной целевой сущности, полученный обзор может содержать фразы, не связанные с целью, что повышает его обнаруживаемость. . В этой работе мы представляем и оцениваем более сложную технику, основанную на нейронном машинном переводе (NMT), с помощью которой мы можем создавать обзоры, которые остаются по теме. Мы тестируем несколько вариантов нашей техники с участием носителей английского языка на Amazon Mechanical Turk. Мы демонстрируем, что отзывы, созданные по лучшему варианту, имеют почти оптимальную необнаружимость (средний по классу F-показатель 47%). Мы проводим исследование среди скептически настроенных пользователей и показываем, что наш метод ускользает от обнаружения чаще по сравнению с современным (среднее уклонение 3,2/4 против 1,5/4) со статистической значимостью на уровне {\\\\alpha} = 1. % (раздел 4.3). Мы разрабатываем очень эффективные инструменты обнаружения и достигаем среднего показателя F 97% при их классификации. Хотя фейковые отзывы очень эффективны для обмана людей, эффективное автоматическое обнаружение все же возможно.',\n",
       " 'Методы создания карт значимости находятся на переднем крае объяснимой литературы по искусственному интеллекту для широкого спектра приложений машинного обучения. Наша цель — поставить под сомнение пределы этих подходов для решения более сложных задач. В этой статье мы применяем послойное распространение релевантности (LRP) к модели внимания от последовательности к последовательности, обученной на наборе данных суммирования текста. Мы получаем неожиданные карты значимости и обсуждаем правомерность этих «объяснений». Мы утверждаем, что нам нужен количественный способ проверки контрфактического случая, чтобы судить о правдивости карт значимости. Мы предлагаем протокол для проверки достоверности важности, приписываемой входным данным, и показываем, что полученные карты значимости иногда отражают реальное использование входных функций сетью, а иногда нет. Мы используем этот пример, чтобы обсудить, насколько осторожными нам следует быть, принимая их в качестве объяснения.',\n",
       " 'Было показано, что встраивания слов, полученные из больших корпусов, имеют тенденцию включать предвзятости, присутствующие в их обучающих данных. Были предложены различные методы смягчения этих предубеждений, но недавние работы показали, что эти методы скрывают, но не могут по-настоящему устранить предвзятости, которые все еще можно наблюдать в статистике ближайших соседей слов. В этой работе мы предлагаем вероятностный взгляд на предвзятость встраивания слов. Мы используем эту структуру, чтобы представить новый метод уменьшения систематической ошибки, который основан на вероятностных наблюдениях и дает более надежный алгоритм уменьшения систематической ошибки. Мы демонстрируем, что этот метод эффективно снижает предвзятость по трем отдельным показателям предвзятости, сохраняя при этом качество внедрения в различных популярных эталонных семантических задачах.',\n",
       " \"Успех нескольких архитектур в изучении семантических представлений из неаннотированного текста и доступность такого рода текстов в многоязычных онлайн-ресурсах, таких как Википедия, способствовали массовому и автоматическому созданию ресурсов для нескольких языков. Оценка таких ресурсов обычно проводится для языков с высокими ресурсами, где есть шведский стол из задач и наборов тестов для оценки. Для языков с низким уровнем ресурсов оценка более сложна и обычно игнорируется в надежде, что впечатляющая способность архитектур глубокого обучения изучать (многоязычные) представления в условиях с высокими ресурсами сохраняется и в условиях с низкими ресурсами. В этой статье мы концентрируемся на двух африканских языках, йоруб\\\\'а и тви, и сравниваем встраивания слов, полученные таким способом, с встраиваниями слов, полученными из тщательно подобранных корпусов и языково-зависимой обработки. Мы анализируем шум в общедоступных корпусах, собираем качественные и зашумленные данные для двух языков и количественно оцениваем улучшения, которые зависят не только от количества данных, но и от качества. Мы также используем различные архитектуры, которые изучают представления слов как по поверхностным формам, так и по символам, чтобы дополнительно использовать всю доступную информацию, которая оказалась важной для этих языков. Для оценки мы вручную переводим набор данных пар слов wordim-353 с английского на Yor\\\\`ub\\\\'a и Twi. В результате работы мы предоставляем корпуса, встраивания и тестовые наборы для обоих языков.\",\n",
       " 'В этой работе мы предлагаем анализ наличия гендерных предубеждений, связанных с профессиями, в португальских словах. Целью данной работы является изучение гендерных последствий стереотипных профессий для женщин и мужчин в контексте португальского языка.',\n",
       " 'В этой статье мы представляем данные о цитировании высших судов Чехии (Верховный суд, Высший административный суд и Конституционный суд). Этот набор данных был автоматически извлечен из корпуса текстов решений чешских судов – CzCDC 1.0. Мы получили данные о цитировании, построив конвейер обработки естественного языка для извлечения идентификаторов судебных решений. В состав конвейера вошли (i) модель сегментации документов и (ii) модель распознавания ссылок. Кроме того, набор данных был обработан вручную для получения высококачественных данных о цитировании в качестве основы для последующего качественного и количественного анализа. Набор данных будет доступен широкой публике.',\n",
       " 'Психическое здоровье ветеранов является серьезной национальной проблемой, поскольку большое количество ветеранов возвращается с недавней войны в Ираке и продолжающегося военного присутствия в Афганистане. Хотя в существующих значительных работах изучалась оценка посттравматического стрессового расстройства (ПТСР) на основе постов в Твиттере с использованием методов машинного обучения «черный ящик», клиницисты не могут доверять этим основам из-за отсутствия клинической объяснимости. Чтобы завоевать доверие врачей, мы исследуем большой вопрос: могут ли сообщения в Твиттере предоставить достаточно информации для заполнения клинических опросов по оценке посттравматического стрессового расстройства, которым врачи традиционно доверяют? Чтобы ответить на поставленный выше вопрос, мы предлагаем модель LAXARY (объяснимый запрос на основе лингвистического анализа), новую модель объяснимого искусственного интеллекта (XAI) для обнаружения и представления оценки посттравматического стрессового расстройства пользователей Твиттера с использованием модифицированного анализа лингвистического запроса и подсчета слов (LIWC). . Во-первых, мы используем клинически проверенные инструменты опросов для сбора данных клинической оценки посттравматического стрессового расстройства от реальных пользователей Твиттера и разрабатываем лингвистический словарь посттравматического стрессового расстройства, используя результаты опросов по оценке посттравматического стрессового расстройства. Затем мы используем лингвистический словарь посттравматического стрессового расстройства вместе с моделью машинного обучения, чтобы заполнить инструменты опроса для определения статуса посттравматического стрессового расстройства и его интенсивности у соответствующих пользователей Твиттера. Наша экспериментальная оценка 210 клинически проверенных пользователей Твиттера-ветеранов обеспечивает многообещающую точность как классификации посттравматического стрессового расстройства, так и оценки его интенсивности. Мы также оцениваем надежность и достоверность разработанного нами Лингвистического словаря по посттравматическому стрессу.',\n",
       " 'Мы создали этот набор данных CORD-19-NER с комплексным распознаванием именованных объектов (NER) в корпусе набора данных открытых исследований COVID-19 (CORD-19) (13 марта 2020 г.). Этот набор данных CORD-19-NER охватывает 74 детальных именованных типа объектов. Он генерируется автоматически путем объединения результатов аннотаций из четырех источников: (1) предварительно обученная модель NER по 18 общим типам объектов из Spacy, (2) предварительно обученная модель NER по 18 типам биомедицинских объектов из SciSpacy, (3) база знаний Модель NER на основе (KB) для 127 типов биомедицинских объектов с нашим методом NER с дистанционным контролем и (4) модель NER на основе исходных данных для 8 новых типов объектов (в частности, связанных с исследованиями COVID-19) с нашим NER со слабым контролем метод. Мы надеемся, что этот набор данных поможет сообществу интеллектуального анализа текста создавать последующие приложения. Мы также надеемся, что этот набор данных может помочь в исследованиях COVID-19 как с биомедицинской, так и с социальной стороны.',\n",
       " 'В этой статье мы представляем UniSent — универсальную лексику настроений для 1000 языков, созданную с использованием словаря английских настроений и массового параллельного корпуса в области Библии. Насколько нам известно, UniSent на сегодняшний день является крупнейшим ресурсом по настроениям с точки зрения количества охваченных языков, включая многие языки с ограниченными ресурсами. Для создания UniSent мы предлагаем Adapted Sentiment Pivot, новый метод, который сочетает в себе проецирование аннотаций, расширение словарного запаса и неконтролируемую адаптацию предметной области. Мы оцениваем качество UniSent для македонского, чешского, немецкого, испанского и французского языков и показываем, что его качество сопоставимо с ресурсами настроений, созданными вручную или полувручную. Публикуя эту статью, мы выпускаем UniSent lexica, а также коды, связанные с Adapted Sentiment Pivot. метод.',\n",
       " 'Устранение неоднозначности значений слов в контексте легко для людей, но является серьезной проблемой для автоматических подходов. Для решения этой задачи были разработаны сложные контролируемые и основанные на знаниях модели. Однако (i) присущее Ципфу распределение контролируемых примеров обучения для данного слова и/или (ii) качество репрезентаций лингвистических знаний мотивируют разработку совершенно неконтролируемых и не требующих знаний подходов к устранению смысловой неоднозначности слов (WSD). Они особенно полезны для языков с ограниченными ресурсами, в которых нет ресурсов для построения контролируемых моделей и/или моделей, основанных на знаниях. В этой статье мы представляем метод, который принимает в качестве входных данных стандартную предварительно обученную модель встраивания слов и создает полноценный инвентарь смыслов слов, который можно использовать для устранения неоднозначности в контексте. Мы используем этот метод для создания коллекции смысловых инвентаризаций для 158 языков на основе исходных предварительно обученных встраиваний слов fastText, выполненных Grave et al. (2018), включив WSD на этих языках. Модели и система доступны онлайн.',\n",
       " 'Идентификация языка (LI) является важным первым шагом в некоторых системах обработки речи. С ростом числа голосовых помощников речевая LI стала широко исследуемой областью. Чтобы подойти к проблеме идентификации языков, мы можем принять либо неявный подход, при котором присутствует только речь языка, либо явный подход, при котором доступен текст с соответствующей транскрипцией. В данной статье основное внимание уделяется неявному подходу из-за отсутствия транскриптивных данных. В этой статье сравниваются существующие модели и предлагается новая модель языковой идентификации, основанная на внимании, которая использует изображения спектрограммы log-Mel в качестве входных данных. Мы также представляем эффективность необработанных сигналов как характеристик моделей нейронных сетей для задач LI. Для обучения и оценки моделей мы классифицировали шесть языков (английский, французский, немецкий, испанский, русский и итальянский) с точностью 95,4% и четыре языка (английский, французский, немецкий, испанский) с точностью 96,3%, полученные из набор данных VoxForge. Этот подход может быть расширен для включения большего количества языков.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['abstracts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "092594e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Что такое семенной словарь?',\n",
       "  'Какие результаты?',\n",
       "  'Как отношения используются для распространения полярности?',\n",
       "  'Насколько велики данные по Японии?',\n",
       "  'Какие метки доступны в наборе данных для наблюдения?',\n",
       "  'Насколько велики улучшения результатов супервизированного обучения, полученные на небольших размеченных данных, с помощью предлагаемого подхода по сравнению с базовым подходом?',\n",
       "  'Как их модель обучается, используя в основном необработанные данные?',\n",
       "  'Насколько велик семенной словарный запас, используемый для обучения?',\n",
       "  'Насколько большой необработанный корпус используется для обучения?'],\n",
       " ['Сообщается ли в документе о макросе F1?',\n",
       "  'Как оценивается эксперимент с аннотациями?',\n",
       "  'Чем формализуются эстетические эмоции?'],\n",
       " ['Они сообщают результаты только по английским данным?',\n",
       "  'Как различные рассмотренные социальные явления проявляются в разных типах сообществ?',\n",
       "  'Какие закономерности в том, как вовлеченность пользователей варьируется в зависимости от характеристик сообщества, они наблюдают?',\n",
       "  'Как были выбраны 300 сообществ Reddit для сравнения?',\n",
       "  'Как авторы измеряют, насколько динамично сообщество во времени?',\n",
       "  'Как авторы измеряют самобытность сообщества?'],\n",
       " ['На каких данных предварительно обучается языковая модель?',\n",
       "  'С какими базовыми показателями сравнивается предлагаемая модель?',\n",
       "  'Как определяется задача структурирования клинического текста?',\n",
       "  'Какие конкретные задачи унифицируются?',\n",
       "  'Весь текст в этом наборе данных представляет собой вопрос или между вопросами есть несвязанные предложения?',\n",
       "  'Сколько вопросов в наборе данных?',\n",
       "  'Что такое perКакие задачи оцениваются?',\n",
       "  'Существуют ли проблемы конфиденциальности клинических данных?',\n",
       "  'Как они вводят специфичные для предметной области функции в предварительно обученную языковую модель?',\n",
       "  'Насколько велик набор данных задач QA-CTS?',\n",
       "  'Насколько велик набор данных отчетов о патологиях, собранных в больнице Жуйцзин?',\n",
       "  'Каковы надежные базовые модели для конкретных задач?'],\n",
       " ['Какие аспекты сравнивались между различными языковыми моделями?',\n",
       "  'какие классические модели языка упоминаются в статье?',\n",
       "  'Какова обычно используемая метрика оценки языковых моделей?'],\n",
       " ['Какой набор данных они используют в качестве отправной точки для создания фейковых отзывов?',\n",
       "  'Используют ли они предварительно обученную модель NMT для создания обзоров?',\n",
       "  'Как использование NMT гарантирует, что созданные обзоры будут соответствовать теме?',\n",
       "  'Какую модель они используют для обнаружения?',\n",
       "  'Их инструмент обнаружения работает лучше, чем обнаружение людей?',\n",
       "  'Сколько всего отзывов (как созданных, так и реальных) они оценивают на Amazon Mechanical Turk?'],\n",
       " ['Какие базовые показатели они сравнивали?',\n",
       "  'Сколько слоев внимания имеется в их модели?',\n",
       "  'Верно ли объяснение карты значимости?'],\n",
       " ['Как оценивается качество встраивания?',\n",
       "  'Какие три меры систематической ошибки уменьшаются в экспериментах?',\n",
       "  'Какие вероятностные наблюдения способствуют созданию более надежного алгоритма?'],\n",
       " ['Что окажется важнее: большие объемы или высококачественные данные?',\n",
       "  'Насколько модель улучшается за счет массивных данных и насколько за счет качества?',\n",
       "  'Какие две архитектуры используются?'],\n",
       " ['Эта статья ориентирована на европейский или бразильский португальский язык?',\n",
       "  'На чем обучались встраиваниям слов?',\n",
       "  'Какие вложения слов анализируются?'],\n",
       " ['Экспериментировали ли они с этим набором данных?',\n",
       "  'Как измеряется качество цитирования?',\n",
       "  'Насколько велик набор данных?'],\n",
       " ['Они оценивают только наборы данных на английском языке?',\n",
       "  'Упоминают ли авторы какие-либо возможные затруднения в этом исследовании?',\n",
       "  'Как устанавливается интенсивность ПТСР?',\n",
       "  'Как LIWC включен в эту систему?',\n",
       "  'Сколько пользователей Твиттера охвачено клинически проверенным опросом?',\n",
       "  'Какие клинически проверенные инструменты опроса используются?'],\n",
       " ['Экспериментировали ли они с набором данных?',\n",
       "  'Каков размер этого набора данных?',\n",
       "  'Перечисляют ли они все присутствующие именованные типы сущностей?'],\n",
       " ['как измеряется качество?',\n",
       "  'для скольких языков конкретно предназначена эта лексика?',\n",
       "  'с какими источниками настроений они сравниваются?'],\n",
       " ['Является ли метод, описанный в этой работе, методом, основанным на кластеризации?',\n",
       "  'Как аннотируются/маркируются различные чувства?',\n",
       "  'Проводилась ли какая-либо внешняя оценка?'],\n",
       " ['Использует ли модель как изображения спектрограмм, так и необработанные сигналы в качестве функций?',\n",
       "  'Сравнивается ли производительность с базовой моделью?',\n",
       "  'Какова точность, которую показывают современные методы?']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1d67f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['titles', 'abstracts', 'texts', 'questions', 'answeres', 'evidences'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "011f1ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['словарь положительных и отрицательных предикатов, который помогает определить оценку полярности события',\n",
       "  'Использование всех данных для обучения: AL — BiGRU достиг точности 0,843, AL — BERT достиг точности 0,863, AL+CA+CO — BiGRU достиг точности 0,866, AL+CA+CO — BERT достиг точности 0,835, ACP — BiGRU достиг точности 0,919, ACP -- BERT достиг точности 0,933, ACP+AL+CA+CO -- BiGRU достиг точности 0,917, ACP+AL+CA+CO -- BERT достиг точности 0,913.\\nИспользование подмножества для обучения: BERT достиг точности 0,876 с использованием ACP (6K), BERT достиг точности 0,886 с использованием ACP (6K) + AL, BiGRU достиг точности 0,830 с использованием ACP (6K), BiGRU достиг точности 0,879 с использованием ACP (6K) + AL + ЦА + СО.',\n",
       "  'исходя из связи между событиями, предполагаемая полярность одного события может определить возможную полярность другого события.',\n",
       "  'Из японского веб-корпуса было извлечено 7000000 пар событий, из корпуса ACP было извлечено 529850 пар событий.',\n",
       "  '',\n",
       "  '3%',\n",
       "  'используя дискурсивные отношения для распространения полярности от исходных предикатов к окончательной полярности чувств.',\n",
       "  '30 слов',\n",
       "  ''],\n",
       " ['', '', ''],\n",
       " ['',\n",
       "  'Динамические сообщества имеют значительно более высокие показатели ежемесячного удержания пользователей, чем более стабильные сообщества. Более самобытные сообщества демонстрируют умеренно более высокие ежемесячные показатели удержания, чем более общие сообщества. Существует также сильная положительная взаимосвязь между динамикой сообщества и средним количеством месяцев, в течение которых пользователь остается в этом сообществе: краткосрочная тенденция, наблюдаемая для ежемесячного удержания, приводит к более долгосрочному участию и предполагает, что долгосрочное удержание пользователей может во многом зависит от того, насколько сообщество постоянно предоставляет новый контент.',\n",
       "  '',\n",
       "  'Они выбрали все сабреддиты с января 2013 по декабрь 2014 года со словарным запасом не менее 500 слов и историей сабреддита не менее 4 месяцев. Они также удалили сообщества, большая часть которых написана на иностранном языке.',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'набор данных состоит из отчетов о патологии, включая предложения, вопросы и ответы о размере опухоли и границах резекции, поэтому он включает дополнительные предложения.',\n",
       "  '2714',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['Качество измеряется с помощью недоумения и вспоминания, а производительность измеряется с помощью задержки и потребления энергии.',\n",
       "  '',\n",
       "  ''],\n",
       " ['', '', '', '', '', ''],\n",
       " ['', 'один', ''],\n",
       " ['', 'RIPA, Метрика района, WEAT', ''],\n",
       " ['', '', ''],\n",
       " ['', '', ''],\n",
       " ['', '', ''],\n",
       " ['', '', '', '', '', ''],\n",
       " ['', '', ''],\n",
       " ['Точность и макро-F1 (усредненный F1 по положительным и отрицательным классам) используются в качестве меры качества.',\n",
       "  '',\n",
       "  ''],\n",
       " ['', '', ''],\n",
       " ['',\n",
       "  '',\n",
       "  'Ответ без содержания: (Таблица 1)\\nПредыдущее состояние дел в том же наборе данных: ResNet50 89% (6 языков), SVM-HMM 70% (4 языка)']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answeres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4349eb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Семенной лексикон состоит из положительных и отрицательных предикатов. Если предикат извлеченного события находится в исходном лексиконе и не включает в себя сложные явления, такие как отрицание, мы присваиваем событию соответствующую оценку полярности ($+1$ для положительных событий и $-1$ для отрицательных событий). Мы ожидаем, что модель будет автоматически изучать сложные явления посредством распространения меток. В зависимости от наличия оценок и типов дискурсивных отношений мы классифицируем выделенные пары событий на следующие три типа.'],\n",
       " ['FLOAT SELECTED: Таблица 3: Характеристики различных моделей на тестовом наборе ACP.'],\n",
       " ['В этой статье мы предлагаем простой и эффективный метод изучения аффективных событий, который требует лишь очень небольшого исходного словаря и большого исходного корпуса. Как показано на рисунке FigREF1, наша ключевая идея заключается в том, что мы можем использовать дискурсивные отношения BIBREF4 для эффективного распространения полярности из исходных предикатов, которые напрямую сообщают об эмоциях (например, «радоваться» — это позитивно). Предположим, что события $x_1$, $x_2$ находятся в дискурсивном отношении Причина (т. е. $x_1$ вызывает $x_2$). Если исходный лексикон предполагает, что $x_2$ является положительным, то $x_1$ также, скорее всего, будет положительным, поскольку вызывает положительную эмоцию. Тот факт, что $x_2$ известен как отрицательный, указывает на отрицательную полярность $x_1$. Аналогично, если $x_1$ и $x_2$ находятся в дискурсивном отношении Уступка (т. е. $x_2$ несмотря на $x_1$), обратная полярность $x_2$ может быть распространена на $x_1$. Даже если полярность $x_2$ заранее не известна, мы можем использовать тенденцию $x_1$ и $x_2$ иметь одну и ту же полярность (для Причины) или обратную полярность (для Уступки), хотя эвристика не освобождается от контрпримеров. Мы трансформируем эту идею в целевые функции и обучаем модели нейронных сетей, которые предсказывают полярность данного события.'],\n",
       " ['В качестве необработанного корпуса мы использовали японский веб-корпус, который был скомпилирован с помощью процедур, предложенных BIBREF13. Для извлечения пар событий, помеченных дискурсивными отношениями, мы использовали японский анализатор зависимостей KNP и собственные сценарии постобработки BIBREF14. KNP использовал написанные от руки правила для разделения каждого предложения на то, что мы обычно называем предложениями (в основном последовательные фрагменты текста), каждый из которых содержит один главный предикат. KNP также идентифицировал дискурсивные отношения пар событий, если присутствовали явные дискурсивные связки BIBREF4, такие как «ので» (потому что) и «のに» (несмотря на). Мы рассматривали причину/причину (原因・理由) и условие (条件) в исходном наборе тегов BIBREF15 как причину, а уступку (逆接) как уступку соответственно. Вот пример извлечения пары событий.'],\n",
       " ['Аффективные события BIBREF0 — это события, которые обычно влияют на людей положительно или отрицательно. Например, получение денег и занятия спортом обычно оказывают положительное влияние на переживающих; простуда и потеря кошелька – негативны. Понимание аффективных событий важно для различных приложений обработки естественного языка (НЛП), таких как диалоговые системы BIBREF1, системы вопросов-ответов BIBREF2 и системы распознавания юмора BIBREF3. В этой статье мы работаем над распознаванием полярности аффективного события, которое представлено оценкой в \\u200b\\u200bдиапазоне от $-1$ (отрицательный) до 1 (положительный).'],\n",
       " ['FLOAT SELECTED: Таблица 4: Результаты для небольших помеченных обучающих данных. Учитывая производительность с полным набором данных, мы показываем, что BERT обучен только с данными AL.'],\n",
       " ['В этой статье мы предлагаем простой и эффективный метод изучения аффективных событий, который требует лишь очень небольшого исходного словаря и большого исходного корпуса. Как показано на рисунке FigREF1, наша ключевая идея заключается в том, что мы можем использовать дискурсивные отношения BIBREF4 для эффективного распространения полярности из исходных предикатов, которые напрямую сообщают об эмоциях (например, «радоваться» — это позитивно). Предположим, что события $x_1$, $x_2$ находятся в дискурсивном отношении Причина (т. е. $x_1$ вызывает $x_2$). Если исходный лексикон предполагает, что $x_2$ является положительным, то $x_1$ также, скорее всего, будет положительным, поскольку вызывает положительную эмоцию. Тот факт, что $x_2$ известен как отрицательный, указывает на отрицательную полярность $x_1$. Аналогично, если $x_1$ и $x_2$ находятся в дискурсивном отношении Уступка (т. е. $x_2$ несмотря на $x_1$), обратная полярность $x_2$ может быть распространена на $x_1$. Даже если полярность $x_2$ заранее не известна, мы можем использовать тенденцию $x_1$ и $x_2$ иметь одну и ту же полярность (для Причины) или обратную полярность (для Уступки), хотя эвристика не освобождается от контрпримеров. Мы трансформируем эту идею в целевые функции и обучаем модели нейронных сетей, которые предсказывают полярность данного события.'],\n",
       " ['Мы построили наш начальный словарь, состоящий из 15 положительных слов и 15 отрицательных слов, как показано в разделе SECREF27. Из корпуса, состоящего примерно из 100 миллионов предложений, мы получили 1,4 миллиона пар событий для AL, 41 миллион для CA и 6 миллионов для CO. Мы случайным образом выбрали подмножества пар событий AL так, чтобы положительные и отрицательные последние события были равны по размеру. Мы также выбрали пары событий для каждого из CA и CO, так что они были в пять раз больше, чем AL. Результаты показаны в таблице TABREF16.'],\n",
       " ['В качестве необработанного корпуса мы использовали японский веб-корпус, который был скомпилирован с помощью процедур, предложенных BIBREF13. Для извлечения пар событий, помеченных дискурсивными отношениями, мы использовали японский анализатор зависимостей KNP и собственные сценарии постобработки BIBREF14. KNP использовал написанные от руки правила для разделения каждого предложения на то, что мы обычно называем предложениями (в основном последовательные фрагменты текста), каждый из которых содержит один главный предикат. KNP также идентифицировал дискурсивные отношения пар событий, если присутствовали явные дискурсивные связки BIBREF4, такие как «ので» (потому что) и «のに» (несмотря на). Мы рассматривали причину/причину (原因・理由) и условие (条件) в исходном наборе тегов BIBREF15 как причину, а уступку (逆接) как уступку соответственно. Вот пример извлечения пары событий.']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['evidences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "086c8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qae:\n",
    "    def __init__(self, ques, ans, evi):\n",
    "        self.ques = ques\n",
    "        self.ans = ans\n",
    "        self.evi = evi\n",
    "    def show(self, n, show_evi = True):\n",
    "        print('QUESTION ' + str(n + 1) + ':')\n",
    "        print(self.ques)\n",
    "        print('-------')\n",
    "        print('ANSWER ' + str(n + 1) + ':')\n",
    "        print(self.ans)\n",
    "        print('-------')\n",
    "        \n",
    "        if show_evi:\n",
    "            print('EVIDENCE ' + str(n + 1) + ':')\n",
    "            print(self.evi)\n",
    "            print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b208ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qas(data, n, show_evi = True):\n",
    "    print('TITLE: ' + data['titles'][n])\n",
    "    print('-------')\n",
    "    print('ABSTRACT: ' + data['abstracts'][n])\n",
    "    print('-------')\n",
    "    \n",
    "    for i in range(0,len(data['questions'][n])):\n",
    "        try:\n",
    "            q = data['questions'][n][i]\n",
    "        except:\n",
    "            q = ''\n",
    "            \n",
    "        try:\n",
    "            a = data['answeres'][n][i]\n",
    "        except:\n",
    "            a = ''\n",
    "        \n",
    "        try:\n",
    "            e = data['evidences'][n][i]\n",
    "        except:\n",
    "            e = ''\n",
    "            \n",
    "        q_a_e = qae(q, a, e)\n",
    "        q_a_e.show(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77d918d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Обучение аффективным событиям с минимальным контролем с использованием дискурсивных отношений\n",
      "-------\n",
      "ABSTRACT: Распознавание аффективных событий, которые вызывают положительные или отрицательные эмоции, имеет широкий спектр приложений для обработки естественного языка, но остается сложной проблемой, главным образом потому, что полярность события не обязательно предсказуема по составляющим его словам. В этой статье мы предлагаем пропагандировать аффективную полярность с помощью дискурсивных отношений. Наш метод прост и требует лишь очень небольшого исходного словаря и большого необработанного корпуса. Наши эксперименты с использованием японских данных показывают, что наш метод эффективно изучает аффективные события без маркировки данных вручную. Это также улучшает результаты контролируемого обучения, когда помеченные данные малы.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Что такое семенной словарь?\n",
      "-------\n",
      "ANSWER 1:\n",
      "словарь положительных и отрицательных предикатов, который помогает определить оценку полярности события\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Семенной лексикон состоит из положительных и отрицательных предикатов. Если предикат извлеченного события находится в исходном лексиконе и не включает в себя сложные явления, такие как отрицание, мы присваиваем событию соответствующую оценку полярности ($+1$ для положительных событий и $-1$ для отрицательных событий). Мы ожидаем, что модель будет автоматически изучать сложные явления посредством распространения меток. В зависимости от наличия оценок и типов дискурсивных отношений мы классифицируем выделенные пары событий на следующие три типа.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Какие результаты?\n",
      "-------\n",
      "ANSWER 2:\n",
      "Использование всех данных для обучения: AL — BiGRU достиг точности 0,843, AL — BERT достиг точности 0,863, AL+CA+CO — BiGRU достиг точности 0,866, AL+CA+CO — BERT достиг точности 0,835, ACP — BiGRU достиг точности 0,919, ACP -- BERT достиг точности 0,933, ACP+AL+CA+CO -- BiGRU достиг точности 0,917, ACP+AL+CA+CO -- BERT достиг точности 0,913.\n",
      "Использование подмножества для обучения: BERT достиг точности 0,876 с использованием ACP (6K), BERT достиг точности 0,886 с использованием ACP (6K) + AL, BiGRU достиг точности 0,830 с использованием ACP (6K), BiGRU достиг точности 0,879 с использованием ACP (6K) + AL + ЦА + СО.\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['FLOAT SELECTED: Таблица 3: Характеристики различных моделей на тестовом наборе ACP.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Как отношения используются для распространения полярности?\n",
      "-------\n",
      "ANSWER 3:\n",
      "исходя из связи между событиями, предполагаемая полярность одного события может определить возможную полярность другого события.\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['В этой статье мы предлагаем простой и эффективный метод изучения аффективных событий, который требует лишь очень небольшого исходного словаря и большого исходного корпуса. Как показано на рисунке FigREF1, наша ключевая идея заключается в том, что мы можем использовать дискурсивные отношения BIBREF4 для эффективного распространения полярности из исходных предикатов, которые напрямую сообщают об эмоциях (например, «радоваться» — это позитивно). Предположим, что события $x_1$, $x_2$ находятся в дискурсивном отношении Причина (т. е. $x_1$ вызывает $x_2$). Если исходный лексикон предполагает, что $x_2$ является положительным, то $x_1$ также, скорее всего, будет положительным, поскольку вызывает положительную эмоцию. Тот факт, что $x_2$ известен как отрицательный, указывает на отрицательную полярность $x_1$. Аналогично, если $x_1$ и $x_2$ находятся в дискурсивном отношении Уступка (т. е. $x_2$ несмотря на $x_1$), обратная полярность $x_2$ может быть распространена на $x_1$. Даже если полярность $x_2$ заранее не известна, мы можем использовать тенденцию $x_1$ и $x_2$ иметь одну и ту же полярность (для Причины) или обратную полярность (для Уступки), хотя эвристика не освобождается от контрпримеров. Мы трансформируем эту идею в целевые функции и обучаем модели нейронных сетей, которые предсказывают полярность данного события.']\n",
      "-------\n",
      "QUESTION 4:\n",
      "Насколько велики данные по Японии?\n",
      "-------\n",
      "ANSWER 4:\n",
      "Из японского веб-корпуса было извлечено 7000000 пар событий, из корпуса ACP было извлечено 529850 пар событий.\n",
      "-------\n",
      "EVIDENCE 4:\n",
      "['В качестве необработанного корпуса мы использовали японский веб-корпус, который был скомпилирован с помощью процедур, предложенных BIBREF13. Для извлечения пар событий, помеченных дискурсивными отношениями, мы использовали японский анализатор зависимостей KNP и собственные сценарии постобработки BIBREF14. KNP использовал написанные от руки правила для разделения каждого предложения на то, что мы обычно называем предложениями (в основном последовательные фрагменты текста), каждый из которых содержит один главный предикат. KNP также идентифицировал дискурсивные отношения пар событий, если присутствовали явные дискурсивные связки BIBREF4, такие как «ので» (потому что) и «のに» (несмотря на). Мы рассматривали причину/причину (原因・理由) и условие (条件) в исходном наборе тегов BIBREF15 как причину, а уступку (逆接) как уступку соответственно. Вот пример извлечения пары событий.']\n",
      "-------\n",
      "QUESTION 5:\n",
      "Какие метки доступны в наборе данных для наблюдения?\n",
      "-------\n",
      "ANSWER 5:\n",
      "\n",
      "-------\n",
      "EVIDENCE 5:\n",
      "['Аффективные события BIBREF0 — это события, которые обычно влияют на людей положительно или отрицательно. Например, получение денег и занятия спортом обычно оказывают положительное влияние на переживающих; простуда и потеря кошелька – негативны. Понимание аффективных событий важно для различных приложений обработки естественного языка (НЛП), таких как диалоговые системы BIBREF1, системы вопросов-ответов BIBREF2 и системы распознавания юмора BIBREF3. В этой статье мы работаем над распознаванием полярности аффективного события, которое представлено оценкой в \\u200b\\u200bдиапазоне от $-1$ (отрицательный) до 1 (положительный).']\n",
      "-------\n",
      "QUESTION 6:\n",
      "Насколько велики улучшения результатов супервизированного обучения, полученные на небольших размеченных данных, с помощью предлагаемого подхода по сравнению с базовым подходом?\n",
      "-------\n",
      "ANSWER 6:\n",
      "3%\n",
      "-------\n",
      "EVIDENCE 6:\n",
      "['FLOAT SELECTED: Таблица 4: Результаты для небольших помеченных обучающих данных. Учитывая производительность с полным набором данных, мы показываем, что BERT обучен только с данными AL.']\n",
      "-------\n",
      "QUESTION 7:\n",
      "Как их модель обучается, используя в основном необработанные данные?\n",
      "-------\n",
      "ANSWER 7:\n",
      "используя дискурсивные отношения для распространения полярности от исходных предикатов к окончательной полярности чувств.\n",
      "-------\n",
      "EVIDENCE 7:\n",
      "['В этой статье мы предлагаем простой и эффективный метод изучения аффективных событий, который требует лишь очень небольшого исходного словаря и большого исходного корпуса. Как показано на рисунке FigREF1, наша ключевая идея заключается в том, что мы можем использовать дискурсивные отношения BIBREF4 для эффективного распространения полярности из исходных предикатов, которые напрямую сообщают об эмоциях (например, «радоваться» — это позитивно). Предположим, что события $x_1$, $x_2$ находятся в дискурсивном отношении Причина (т. е. $x_1$ вызывает $x_2$). Если исходный лексикон предполагает, что $x_2$ является положительным, то $x_1$ также, скорее всего, будет положительным, поскольку вызывает положительную эмоцию. Тот факт, что $x_2$ известен как отрицательный, указывает на отрицательную полярность $x_1$. Аналогично, если $x_1$ и $x_2$ находятся в дискурсивном отношении Уступка (т. е. $x_2$ несмотря на $x_1$), обратная полярность $x_2$ может быть распространена на $x_1$. Даже если полярность $x_2$ заранее не известна, мы можем использовать тенденцию $x_1$ и $x_2$ иметь одну и ту же полярность (для Причины) или обратную полярность (для Уступки), хотя эвристика не освобождается от контрпримеров. Мы трансформируем эту идею в целевые функции и обучаем модели нейронных сетей, которые предсказывают полярность данного события.']\n",
      "-------\n",
      "QUESTION 8:\n",
      "Насколько велик семенной словарный запас, используемый для обучения?\n",
      "-------\n",
      "ANSWER 8:\n",
      "30 слов\n",
      "-------\n",
      "EVIDENCE 8:\n",
      "['Мы построили наш начальный словарь, состоящий из 15 положительных слов и 15 отрицательных слов, как показано в разделе SECREF27. Из корпуса, состоящего примерно из 100 миллионов предложений, мы получили 1,4 миллиона пар событий для AL, 41 миллион для CA и 6 миллионов для CO. Мы случайным образом выбрали подмножества пар событий AL так, чтобы положительные и отрицательные последние события были равны по размеру. Мы также выбрали пары событий для каждого из CA и CO, так что они были в пять раз больше, чем AL. Результаты показаны в таблице TABREF16.']\n",
      "-------\n",
      "QUESTION 9:\n",
      "Насколько большой необработанный корпус используется для обучения?\n",
      "-------\n",
      "ANSWER 9:\n",
      "\n",
      "-------\n",
      "EVIDENCE 9:\n",
      "['В качестве необработанного корпуса мы использовали японский веб-корпус, который был скомпилирован с помощью процедур, предложенных BIBREF13. Для извлечения пар событий, помеченных дискурсивными отношениями, мы использовали японский анализатор зависимостей KNP и собственные сценарии постобработки BIBREF14. KNP использовал написанные от руки правила для разделения каждого предложения на то, что мы обычно называем предложениями (в основном последовательные фрагменты текста), каждый из которых содержит один главный предикат. KNP также идентифицировал дискурсивные отношения пар событий, если присутствовали явные дискурсивные связки BIBREF4, такие как «ので» (потому что) и «のに» (несмотря на). Мы рассматривали причину/причину (原因・理由) и условие (条件) в исходном наборе тегов BIBREF15 как причину, а уступку (逆接) как уступку соответственно. Вот пример извлечения пары событий.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96509a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: ПО-ЭМО: концептуализация, аннотация и моделирование эстетических эмоций в немецкой и английской поэзии\n",
      "-------\n",
      "ABSTRACT: Большинство подходов к анализу эмоций в социальных сетях, литературе, новостях и других областях сосредоточены исключительно на базовых категориях эмоций, определенных Экманом или Плутчиком. Однако искусство (например, литература) позволяет проявлять более широкий спектр более сложных и тонких эмоций, которые, как было показано, также включают смешанные эмоциональные реакции. Мы рассматриваем эмоции такими, какие они вызывают у читателя, а не то, что выражено в тексте или задумано автором. Таким образом, мы концептуализируем набор эстетических эмоций, которые предсказывают эстетическое восприятие читателя, и позволяем аннотировать несколько ярлыков в строке, чтобы уловить смешанные эмоции в контексте. Мы оцениваем этот новый сеттинг в эксперименте с аннотациями как с тщательно подготовленными экспертами, так и с помощью краудсорсинга. Наша аннотация с экспертами приводит к приемлемому соглашению каппа = 0,70, что приводит к созданию согласованного набора данных для будущего крупномасштабного анализа. Наконец, мы проводим первые эксперименты по классификации эмоций на основе BERT, показывая, что идентифицировать эстетические эмоции по нашим данным сложно: до 0,52 F1-микро в немецкой подгруппе. Данные и ресурсы доступны по адресу https://github.com/tnhaider/poetry-emotion.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Сообщается ли в документе о макросе F1?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['ВЫБРАНО С FLOAT: Таблица 7: Показатели запоминаемости и точности лучшей модели (dbmdz) для каждой эмоции в тестовом наборе. «Поддержка» означает количество меток.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Как оценивается эксперимент с аннотациями?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Мы обнаружили, что согласие Коэна $\\\\kappa $ варьируется от 0,84 для беспокойства в английских данных, 0,81 для юмора и ностальгии до немецкого напряжения (0,65), трепета/возвышенного (0,61) и жизненной силы для обоих языков (. 50 английских, 0,63 немецких). Оба аннотатора имеют схожий профиль частоты эмоций, причем рейтинг практически одинаков, особенно для немецкого языка. Однако для английского языка Аннотатор 2 аннотирует больше «Жизнеспособность», чем «Беспокойство». На рисунке FigREF18 показаны матрицы путаницы меток между аннотаторами в виде тепловых карт. Примечательно, что комментаторы чаще путают «Красоту/Радость» и «Печаль», чем другие ярлыки. Это актуально для поэзии и поэтому неудивительно: можно возразить, что красота существ и ситуаций прекрасна только потому, что она непостоянна и, следовательно, не отделяется от печали исчезновения красоты BIBREF48. Мы также обнаруживаем значительную путаницу Печали с Трепетом/Возвышенностью и Жизнеспособностью, тогда как последнюю также регулярно путают с Красотой/Радостью.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Чем формализуются эстетические эмоции?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['Эмоционально тронуть читателей считается главной целью литературы со времен латинской древности BIBREF1, BIBREF2, BIBREF3. Глубоко растроганные читатели плачут, у них озноб и мурашки по коже даже в лабораторных условиях BIBREF4. В подобных случаях эмоциональный отклик фактически подразумевает эстетическую оценку: именно по этой причине повествования, способные тронуть читателей, оцениваются как хорошие и сильные тексты. Точно так же чувство ожидания, испытываемое в повествованиях, не только реагирует на траекторию содержания сюжета, но также напрямую предсказывает эстетическую симпатию (или антипатию). Эмоции, демонстрирующие эту двойную способность, были определены как «эстетические эмоции» BIBREF2. В отличие от негативной предвзятости классических каталогов эмоций, термины эмоций, используемые в целях эстетической оценки, включают гораздо больше положительных, чем отрицательных эмоций. В то же время многие общие положительные эстетические эмоции включают в себя отрицательные или смешанные эмоциональные компоненты BIBREF2, например, чувство ожидания включает в себя как надежду, так и страх.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "baa04813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Идентичность сообщества и вовлечение пользователей в среду, состоящую из нескольких сообществ\n",
      "-------\n",
      "ABSTRACT: Идентичность сообщества определяет и формирует его внутреннюю динамику. Наше нынешнее понимание этого взаимодействия в основном ограничивается взглядами, полученными в результате изолированных исследований отдельных сообществ. В этой работе мы обеспечиваем систематическое исследование природы этих отношений в самых разных онлайн-сообществах. С этой целью мы вводим количественную, основанную на языке типологию, отражающую два ключевых аспекта идентичности сообщества: насколько оно самобытно и насколько оно динамично во времени. Сопоставляя почти 300 сообществ Reddit с ландшафтом, созданным этой типологией, мы выявляем закономерности в том, как модели взаимодействия пользователей варьируются в зависимости от характеристик сообщества. Наши результаты показывают, что способ взаимодействия новых и существующих пользователей с сообществом сильно и систематически зависит от природы коллективной идентичности, которую оно воспитывает, и это имеет большое значение для тех, кто поддерживает сообщество. Например, сообщества с отличительной и очень динамичной идентичностью с большей вероятностью сохранят своих пользователей. Однако такие нишевые сообщества также демонстрируют гораздо больший разрыв в культуре между существующими пользователями и новичками, что потенциально препятствует интеграции последних. В более общем плане наша методология выявляет различия в том, как различные социальные явления проявляются в разных сообществах, и показывает, что структурирование многосообществного ландшафта может привести к лучшему пониманию систематического характера этого разнообразия.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Они сообщают результаты только по английским данным?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Наш полный набор данных состоит из всех субреддитов Reddit с января 2013 по декабрь 2014 года, для которых в словаре, используемом для оценки наших показателей, имеется не менее 500 слов за как минимум 4 месяца истории субреддита. Мы вычисляем наши показатели по комментариям, написанным пользователями в сообществе, во временных интервалах в несколько месяцев для каждого достаточно активного месяца и вручную удаляем сообщества, в которых основная часть комментариев написана на иностранном языке. В результате получается 283 сообщества ( INLINEFORM0 ), что в общей сложности составляет 4872 месяца сообщества ( INLINEFORM1 ).']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Как различные рассмотренные социальные явления проявляются в разных типах сообществ?\n",
      "-------\n",
      "ANSWER 2:\n",
      "Динамические сообщества имеют значительно более высокие показатели ежемесячного удержания пользователей, чем более стабильные сообщества. Более самобытные сообщества демонстрируют умеренно более высокие ежемесячные показатели удержания, чем более общие сообщества. Существует также сильная положительная взаимосвязь между динамикой сообщества и средним количеством месяцев, в течение которых пользователь остается в этом сообществе: краткосрочная тенденция, наблюдаемая для ежемесячного удержания, приводит к более долгосрочному участию и предполагает, что долгосрочное удержание пользователей может во многом зависит от того, насколько сообщество постоянно предоставляет новый контент.\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Мы обнаружили, что динамичные сообщества, такие как Seahawks или Starcraft, имеют значительно более высокие показатели ежемесячного удержания пользователей, чем более стабильные сообщества (INLINEFORM0 Спирмена = 0,70, INLINEFORM1 0,001, вычислено с использованием баллов сообщества, усредненных за несколько месяцев; рисунок FigREF11.A, слева). Аналогичным образом, более самобытные сообщества, такие как Кулинария и Наруто, демонстрируют умеренно более высокие ежемесячные показатели удержания, чем более общие сообщества (INLINEFORM2 Спирмена = 0,33, INLINEFORM3 0,001; рисунок FigREF11.A, справа).']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какие закономерности в том, как вовлеченность пользователей варьируется в зависимости от характеристик сообщества, они наблюдают?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['Вовлеченность и идентичность сообщества. Мы применяем нашу структуру, чтобы понять, как два важных аспекта взаимодействия пользователей в сообществе — склонность сообщества удерживать своих пользователей (раздел SECREF3) и его проницаемость для новых членов (раздел SECREF4) — различаются в зависимости от типа коллективной идентичности, которую оно поощряет. . Мы обнаружили, что сообщества, характеризующиеся специализированным, постоянно обновляемым контентом, имеют более высокие показатели удержания пользователей, но также демонстрируют большие языковые различия, которые отделяют новичков от постоянных участников.']\n",
      "-------\n",
      "QUESTION 4:\n",
      "Как были выбраны 300 сообществ Reddit для сравнения?\n",
      "-------\n",
      "ANSWER 4:\n",
      "Они выбрали все сабреддиты с января 2013 по декабрь 2014 года со словарным запасом не менее 500 слов и историей сабреддита не менее 4 месяцев. Они также удалили сообщества, большая часть которых написана на иностранном языке.\n",
      "-------\n",
      "EVIDENCE 4:\n",
      "['Наш полный набор данных состоит из всех субреддитов Reddit с января 2013 по декабрь 2014 года, для которых в словаре, используемом для оценки наших показателей, имеется не менее 500 слов за как минимум 4 месяца истории субреддита. Мы вычисляем наши показатели по комментариям, написанным пользователями в сообществе, во временных интервалах в несколько месяцев для каждого достаточно активного месяца и вручную удаляем сообщества, в которых основная часть комментариев написана на иностранном языке. В результате получается 283 сообщества ( INLINEFORM0 ), что в общей сложности составляет 4872 месяца сообщества ( INLINEFORM1 ).']\n",
      "-------\n",
      "QUESTION 5:\n",
      "Как авторы измеряют, насколько динамично сообщество во времени?\n",
      "-------\n",
      "ANSWER 5:\n",
      "\n",
      "-------\n",
      "EVIDENCE 5:\n",
      "['Динамичность. Высокодинамичное сообщество постоянно перемещает интересы из одного временного окна в другое, и эти временные изменения отражаются в использовании им изменчивого языка. Формально мы определяем динамику сообщества INLINEFORM0 как среднюю волатильность всех высказываний в INLINEFORM1. Мы называем сообщество, язык которого относительно постоянен во времени, стабильным.']\n",
      "-------\n",
      "QUESTION 6:\n",
      "Как авторы измеряют самобытность сообщества?\n",
      "-------\n",
      "ANSWER 6:\n",
      "\n",
      "-------\n",
      "EVIDENCE 6:\n",
      "['Отличительность. Сообщество с очень своеобразной идентичностью, как правило, имеет особые интересы, выражаемые посредством специализированного языка. Формально мы определяем отличительность сообщества INLINEFORM0 как среднюю специфичность всех высказываний в INLINEFORM1. Мы называем сообщество с менее выраженной идентичностью родовым.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "870d765b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Структурирование клинического текста на основе ответов на вопросы с использованием предварительно обученной языковой модели\n",
      "-------\n",
      "ABSTRACT: Структурирование клинического текста является важнейшей и фундаментальной задачей клинических исследований. Традиционные методы, такие как сквозные модели для конкретных задач и модели конвейеров, обычно страдают от недостатка набора данных и распространения ошибок. В этой статье мы представляем задачу структурирования клинического текста (QA-CTS) на основе ответов на вопросы, позволяющую унифицировать различные конкретные задачи и сделать набор данных доступным для совместного использования. Для задачи QA-CTS также предлагается новая модель, целью которой является внедрение специфичных для предметной области функций (например, информации о клиническом названии объекта) в предварительно обученную языковую модель. Экспериментальные результаты отчетов о патологиях в Китае, собранных в больнице Жуйцзин, показывают, что представленная нами задача QA-CTS очень эффективна для улучшения производительности при выполнении конкретных задач. Предложенная нами модель также выгодно конкурирует с сильными базовыми моделями в конкретных задачах.\n",
      "-------\n",
      "QUESTION 1:\n",
      "На каких данных предварительно обучается языковая модель?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Для реализации моделей глубоких нейронных сетей мы используем библиотеку Keras BIBREF36 с бэкэндом TensorFlow BIBREF37. Каждая модель работает на одном графическом процессоре NVIDIA GeForce GTX 1080 Ti. Модели обучаются с помощью алгоритма оптимизации Адама BIBREF38, параметры которого такие же, как и настройки по умолчанию, за исключением скорости обучения, равной $5\\\\times 10^{-5}$. Размер пакета установлен на 3 или 4 из-за нехватки графической памяти. В этой статье мы выбираем BERT-базу в качестве предварительно обученной языковой модели. Из-за высокой стоимости предварительного обучения языковой модели BERT мы напрямую принимаем параметры, предварительно обученные Google, в общем корпусе китайского языка. Распознавание именованного объекта применяется как к текстам отчетов о патологии, так и к текстам запросов.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "С какими базовыми показателями сравнивается предлагаемая модель?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Экспериментальные исследования ::: Сравнение с современными методами']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Как определяется задача структурирования клинического текста?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['FLOAT SELECTED: Рис. 1. Наглядный пример задачи QA-CTS.']\n",
      "-------\n",
      "QUESTION 4:\n",
      "Какие конкретные задачи унифицируются?\n",
      "-------\n",
      "ANSWER 4:\n",
      "\n",
      "-------\n",
      "EVIDENCE 4:\n",
      "['Чтобы уменьшить глубину конвейера и преодолеть барьер неоднородных выходных форматов, мы представляем задачу структурирования клинического текста на основе ответов на вопросы (QA-CTS) (см. Рис. РИС. РИС. 1). В отличие от традиционной задачи CTS, наша задача QA-CTS направлена \\u200b\\u200bна обнаружение наиболее связанного текста из исходного текста абзаца. В некоторых случаях это уже окончательный ответ на деле (например, извлечение подстроки). В других случаях для получения окончательного ответа требуется несколько шагов, таких как преобразование имен объектов и распознавание отрицательных слов. Представленная нами задача QA-CTS унифицирует формат вывода традиционной задачи CTS и делает данные обучения общедоступными, тем самым обогащая данные обучения. Основные результаты этой работы можно резюмировать следующим образом.']\n",
      "-------\n",
      "QUESTION 5:\n",
      "Весь текст в этом наборе данных представляет собой вопрос или между вопросами есть несвязанные предложения?\n",
      "-------\n",
      "ANSWER 5:\n",
      "набор данных состоит из отчетов о патологии, включая предложения, вопросы и ответы о размере опухоли и границах резекции, поэтому он включает дополнительные предложения.\n",
      "-------\n",
      "EVIDENCE 5:\n",
      "['Наш набор данных аннотирован на основе китайских отчетов о патологии, предоставленных отделением желудочно-кишечной хирургии больницы Жуйджин. Он содержит 17 833 предложения, 826 987 символов и 2714 пар вопрос-ответ. Все пары вопросов и ответов аннотируются и проверяются четырьмя врачами с тремя типами вопросов, а именно размером опухоли, проксимальным краем резекции и дистальным краем резекции. Эти аннотированные экземпляры были разделены на 1899 обучающих экземпляров (12 412 предложений) и 815 тестовых экземпляров (5 421 предложение). Каждый экземпляр имеет одно или несколько предложений. Подробная статистика по различным типам организаций приведена в таблице TABREF20.']\n",
      "-------\n",
      "QUESTION 6:\n",
      "Сколько вопросов в наборе данных?\n",
      "-------\n",
      "ANSWER 6:\n",
      "2714\n",
      "-------\n",
      "EVIDENCE 6:\n",
      "['Наш набор данных аннотирован на основе китайских отчетов о патологии, предоставленных отделением желудочно-кишечной хирургии больницы Жуйджин. Он содержит 17 833 предложения, 826 987 символов и 2714 пар вопрос-ответ. Все пары вопросов и ответов аннотируются и проверяются четырьмя врачами с тремя типами вопросов, а именно размером опухоли, проксимальным краем резекции и дистальным краем резекции. Эти аннотированные экземпляры были разделены на 1899 обучающих экземпляров (12 412 предложений) и 815 тестовых экземпляров (5 421 предложение). Каждый экземпляр имеет одно или несколько предложений. Подробная статистика по различным типам организаций приведена в таблице TABREF20.']\n",
      "-------\n",
      "QUESTION 7:\n",
      "Что такое perКакие задачи оцениваются?\n",
      "-------\n",
      "ANSWER 7:\n",
      "\n",
      "-------\n",
      "EVIDENCE 7:\n",
      "\n",
      "-------\n",
      "QUESTION 8:\n",
      "Существуют ли проблемы конфиденциальности клинических данных?\n",
      "-------\n",
      "ANSWER 8:\n",
      "\n",
      "-------\n",
      "EVIDENCE 8:\n",
      "\n",
      "-------\n",
      "QUESTION 9:\n",
      "Как они вводят специфичные для предметной области функции в предварительно обученную языковую модель?\n",
      "-------\n",
      "ANSWER 9:\n",
      "\n",
      "-------\n",
      "EVIDENCE 9:\n",
      "\n",
      "-------\n",
      "QUESTION 10:\n",
      "Насколько велик набор данных задач QA-CTS?\n",
      "-------\n",
      "ANSWER 10:\n",
      "\n",
      "-------\n",
      "EVIDENCE 10:\n",
      "\n",
      "-------\n",
      "QUESTION 11:\n",
      "Насколько велик набор данных отчетов о патологиях, собранных в больнице Жуйцзин?\n",
      "-------\n",
      "ANSWER 11:\n",
      "\n",
      "-------\n",
      "EVIDENCE 11:\n",
      "\n",
      "-------\n",
      "QUESTION 12:\n",
      "Каковы надежные базовые модели для конкретных задач?\n",
      "-------\n",
      "ANSWER 12:\n",
      "\n",
      "-------\n",
      "EVIDENCE 12:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "937bee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Прогресс и компромиссы в моделях нейронного языка\n",
      "-------\n",
      "ABSTRACT: В последние годы мы стали свидетелями резкого перехода к методам, основанным на нейронных сетях, для решения различных задач НЛП. Несомненно, модели нейронного языка (NLM) значительно уменьшили недоумение. Однако этот прогресс приводит к существенному снижению производительности с точки зрения задержки вывода и энергопотребления, что особенно вызывает беспокойство при развертывании на мобильных устройствах. Эта статья, в которой исследуется соотношение качества и производительности различных методов языкового моделирования, является, насколько нам известно, первым, в котором сделано это наблюдение. Мы сравниваем современные NLM с «классическими» LM Кнезера-Нея (KN) с точки зрения энергопотребления, задержки, запутанности и точности прогнозирования, используя два стандартных теста. На Raspberry Pi мы обнаружили, что порядки увеличения задержки и энергопотребления соответствуют меньшим изменениям в недоумении, в то время как на настольном компьютере разница гораздо менее выражена.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Какие аспекты сравнивались между различными языковыми моделями?\n",
      "-------\n",
      "ANSWER 1:\n",
      "Качество измеряется с помощью недоумения и вспоминания, а производительность измеряется с помощью задержки и потребления энергии.\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Для каждой модели мы исследовали недоумение на уровне слова, R@3 при предсказании следующего слова, задержку (мс/кв) и потребление энергии (мДж/кв). Чтобы изучить взаимосвязь недоумения и запоминания, мы собрали индивидуальную статистику недоумения и запоминания для каждого предложения в тестовом наборе.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "какие классические модели языка упоминаются в статье?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['В этой статье мы исследуем компромисс между качеством и производительностью при переходе от ненейронных к нейронным языковым моделям. В частности, мы сравниваем сглаживание Кнезера-Нея, широко распространенное как современное состояние до появления NLM, с лучшими NLM сегодня. Уменьшение недоумения в стандартных наборах данных было хорошо задокументировано BIBREF3, но, насколько нам известно, никто не исследовал компромиссы в производительности. Имея в виду развертывание на мобильном устройстве, мы оцениваем энергопотребление и задержку вывода на Raspberry Pi (который использует ту же архитектуру ARM, что и почти все современные смартфоны). Мы обнаружили, что снижение недоумения в PTB на 2,5 $\\\\times $ приводит к ошеломляющим затратам с точки зрения производительности: вывод с помощью NLM занимает в 49 $\\\\times $ больше времени и требует в 32 $\\\\times $ больше энергии. Более того, мы обнаружили, что впечатляющее снижение недоумения приводит в лучшем случае к скромным улучшениям в предсказании следующего слова, что, возможно, является лучшим показателем для оценки программных клавиатур на смартфоне. Вклад этой статьи является первым известным объяснением этого компромисса между качеством и производительностью. Обратите внимание, что мы воздерживаемся от предписывающих рекомендаций: целесообразность компромисса зависит от приложения. Тем не менее, инженеры НЛП, возможно, должны учитывать эти компромиссы при выборе конкретной рабочей точки.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какова обычно используемая метрика оценки языковых моделей?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['Глубокое обучение, несомненно, продвинуло современный уровень техники во многих задачах обработки естественного языка, от анализа синтаксических зависимостей BIBREF0 до распознавания именованных объектов BIBREF1 и машинного перевода BIBREF2. То же самое, безусловно, относится и к языковому моделированию, где недавние достижения в области нейронных языковых моделей (NLM) привели к значительно более совершенным подходам, измеряемым с использованием стандартных показателей, таких как недоумение BIBREF3, BIBREF4.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12047443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Оставайтесь в курсе темы: создание поддельных обзоров ресторанов с учетом контекста\n",
      "-------\n",
      "ABSTRACT: Автоматически генерируемые фальшивые обзоры ресторанов представляют угрозу для систем онлайн-обзоров. Недавние исследования показали, что пользователям трудно обнаружить сгенерированные компьютером фальшивые отзывы, скрывающиеся среди реальных отзывов о ресторанах. Используемый в данной работе метод (char-LSTM) имеет один недостаток: ему трудно оставаться в контексте, т.е. когда он генерирует обзор для конкретной целевой сущности, полученный обзор может содержать фразы, не связанные с целью, что повышает его обнаруживаемость. . В этой работе мы представляем и оцениваем более сложную технику, основанную на нейронном машинном переводе (NMT), с помощью которой мы можем создавать обзоры, которые остаются по теме. Мы тестируем несколько вариантов нашей техники с участием носителей английского языка на Amazon Mechanical Turk. Мы демонстрируем, что отзывы, созданные по лучшему варианту, имеют почти оптимальную необнаружимость (средний по классу F-показатель 47%). Мы проводим исследование среди скептически настроенных пользователей и показываем, что наш метод ускользает от обнаружения чаще по сравнению с современным (среднее уклонение 3,2/4 против 1,5/4) со статистической значимостью на уровне {\\alpha} = 1. % (раздел 4.3). Мы разрабатываем очень эффективные инструменты обнаружения и достигаем среднего показателя F 97% при их классификации. Хотя фейковые отзывы очень эффективны для обмана людей, эффективное автоматическое обнаружение все же возможно.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Какой набор данных они используют в качестве отправной точки для создания фейковых отзывов?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Мы используем набор данных Yelp Challenge BIBREF2 для генерации фейковых отзывов. Набор данных (август 2017 г.) содержит 2,9 миллиона отзывов о ресторанах с рейтингом от 1 до 5 звезд. Для целей этой работы мы рассматриваем все обзоры как подлинные, написанные людьми, поскольку о широкомасштабном развертывании атак с использованием машинных обзоров еще не сообщалось (сентябрь 2017 г.) BIBREF19. В ходе предварительной обработки мы удаляем непечатаемые символы (не ASCII) и лишние пробелы. Мы отделяем знаки препинания от слов. Мы резервируем 15 000 отзывов для проверки и 3 000 для тестирования, а остальные используем для обучения. Модели NMT требуют параллельного корпуса исходных и целевых предложений, то есть большого набора пар (источник, цель). Мы создали параллельный корпус, создав пары (контекст, обзор) из набора данных. Далее мы опишем, как мы создали контекст ввода.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Используют ли они предварительно обученную модель NMT для создания обзоров?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "Как использование NMT гарантирует, что созданные обзоры будут соответствовать теме?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n",
      "QUESTION 4:\n",
      "Какую модель они используют для обнаружения?\n",
      "-------\n",
      "ANSWER 4:\n",
      "\n",
      "-------\n",
      "EVIDENCE 4:\n",
      "\n",
      "-------\n",
      "QUESTION 5:\n",
      "Их инструмент обнаружения работает лучше, чем обнаружение людей?\n",
      "-------\n",
      "ANSWER 5:\n",
      "\n",
      "-------\n",
      "EVIDENCE 5:\n",
      "\n",
      "-------\n",
      "QUESTION 6:\n",
      "Сколько всего отзывов (как созданных, так и реальных) они оценивают на Amazon Mechanical Turk?\n",
      "-------\n",
      "ANSWER 6:\n",
      "\n",
      "-------\n",
      "EVIDENCE 6:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2c618bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Генерация карт значимости для автоматического суммирования текста\n",
      "-------\n",
      "ABSTRACT: Методы создания карт значимости находятся на переднем крае объяснимой литературы по искусственному интеллекту для широкого спектра приложений машинного обучения. Наша цель — поставить под сомнение пределы этих подходов для решения более сложных задач. В этой статье мы применяем послойное распространение релевантности (LRP) к модели внимания от последовательности к последовательности, обученной на наборе данных суммирования текста. Мы получаем неожиданные карты значимости и обсуждаем правомерность этих «объяснений». Мы утверждаем, что нам нужен количественный способ проверки контрфактического случая, чтобы судить о правдивости карт значимости. Мы предлагаем протокол для проверки достоверности важности, приписываемой входным данным, и показываем, что полученные карты значимости иногда отражают реальное использование входных функций сетью, а иногда нет. Мы используем этот пример, чтобы обсудить, насколько осторожными нам следует быть, принимая их в качестве объяснения.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Какие базовые показатели они сравнивали?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['В этом разделе мы представляем базовую модель See et al. See2017 обучался на наборе данных CNN/Daily Mail. Мы воспроизводим результаты See et al. См. 2017, чтобы затем применить к нему LRP.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Сколько слоев внимания имеется в их модели?\n",
      "-------\n",
      "ANSWER 2:\n",
      "один\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Базовая модель представляет собой глубокую модель кодера/декодера последователь- ности с вниманием. Кодер представляет собой двунаправленную ячейку долговременной краткосрочной памяти (LSTM) BIBREF14, а декодер — одну ячейку LSTM с механизмом внимания. Механизм внимания вычисляется, как в BIBREF9, и мы используем жадный поиск для декодирования. Мы обучаем сквозное обучение, включая встраивание слов. Используемый размер внедрения составляет 128, а размер скрытого состояния ячеек LSTM — 254.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Верно ли объяснение карты значимости?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['Мы показали, что в некоторых случаях карты значимости соответствуют расчетам сети, а это означает, что они действительно выделяют входные функции, на которых сосредоточилась сеть. Но мы также показали, что в некоторых случаях карты значимости не отражают важные входные характеристики. Это побудило нас обсудить тот факт, что этих атрибуций самих по себе недостаточно, и что нам необходимо определить контрфактический случай и проверить его, чтобы измерить, насколько правдивы карты значимости.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8d4c3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Вероятностное смягчение смещения при встраивании слов\n",
      "-------\n",
      "ABSTRACT: Было показано, что встраивания слов, полученные из больших корпусов, имеют тенденцию включать предвзятости, присутствующие в их обучающих данных. Были предложены различные методы смягчения этих предубеждений, но недавние работы показали, что эти методы скрывают, но не могут по-настоящему устранить предвзятости, которые все еще можно наблюдать в статистике ближайших соседей слов. В этой работе мы предлагаем вероятностный взгляд на предвзятость встраивания слов. Мы используем эту структуру, чтобы представить новый метод уменьшения систематической ошибки, который основан на вероятностных наблюдениях и дает более надежный алгоритм уменьшения систематической ошибки. Мы демонстрируем, что этот метод эффективно снижает предвзятость по трем отдельным показателям предвзятости, сохраняя при этом качество внедрения в различных популярных эталонных семантических задачах.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Как оценивается качество встраивания?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Мы оцениваем нашу платформу на встраиваниях fastText, обученных на Wikipedia (2017), корпусе веб-базы UMBC и наборе данных новостей statmt.org (16 миллиардов токенов) BIBREF11. Для простоты во всех вложениях используются только первые 22 000 слов, хотя предварительные результаты показывают, что результаты распространяются на весь корпус. В наших новых методах уменьшения предвзятости для настройки встраивания используется мелкая нейронная сеть. Один слой модели представляет собой слой внедрения с весами, инициализированными в соответствии с весами исходного внедрения. Для составного метода эти веса инициализируются значениями встраивания после уменьшения вероятностного смещения. В модель вводится пакет индексов слов, которые затем встраиваются и для которых рассчитывается значение потерь, что позволяет обратному распространению ошибки корректировать встраивания. Для каждой модели используется фиксированное количество итераций, чтобы предотвратить переобучение, которое в конечном итоге может снизить производительность в тестах внедрения (см. Рисунок РИС. 12). Мы оценивали встраивание после 1000 итераций и прекращали обучение, если производительность в тесте значительно снижалась.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Какие три меры систематической ошибки уменьшаются в экспериментах?\n",
      "-------\n",
      "ANSWER 2:\n",
      "RIPA, Метрика района, WEAT\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Для смягчения геометрической предвзятости используются косинусные расстояния между словами как для измерения, так и для устранения гендерной предвзятости BIBREF0. Этот метод неявно определяет предвзятость как геометрическую асимметрию между словами при проецировании на подпространство, такое как гендерное подпространство, построенное из набора гендерных пар, таких как $\\\\mathcal {P} = \\\\lbrace (он, она), (мужчина, женщина ),(король,королева)...\\\\rbrace $. Проекция вектора $v$ на $B$ (подпространство) определяется формулой $v_B = \\\\sum _{j=1}^{k} (v \\\\cdot b_j) b_j$, где определено подпространство $B$ k ортогональными единичными векторами $B = {b_1,...,b_k}$.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какие вероятностные наблюдения способствуют созданию более надежного алгоритма?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2504a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Массивные и тщательно подобранные встраивания слов для языков с ограниченными ресурсами. Дело Йоруба и Тви\n",
      "-------\n",
      "ABSTRACT: Успех нескольких архитектур в изучении семантических представлений из неаннотированного текста и доступность такого рода текстов в многоязычных онлайн-ресурсах, таких как Википедия, способствовали массовому и автоматическому созданию ресурсов для нескольких языков. Оценка таких ресурсов обычно проводится для языков с высокими ресурсами, где есть шведский стол из задач и наборов тестов для оценки. Для языков с низким уровнем ресурсов оценка более сложна и обычно игнорируется в надежде, что впечатляющая способность архитектур глубокого обучения изучать (многоязычные) представления в условиях с высокими ресурсами сохраняется и в условиях с низкими ресурсами. В этой статье мы концентрируемся на двух африканских языках, йоруб\\'а и тви, и сравниваем встраивания слов, полученные таким способом, с встраиваниями слов, полученными из тщательно подобранных корпусов и языково-зависимой обработки. Мы анализируем шум в общедоступных корпусах, собираем качественные и зашумленные данные для двух языков и количественно оцениваем улучшения, которые зависят не только от количества данных, но и от качества. Мы также используем различные архитектуры, которые изучают представления слов как по поверхностным формам, так и по символам, чтобы дополнительно использовать всю доступную информацию, которая оказалась важной для этих языков. Для оценки мы вручную переводим набор данных пар слов wordim-353 с английского на Yor\\`ub\\'a и Twi. В результате работы мы предоставляем корпуса, встраивания и тестовые наборы для обоих языков.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Что окажется важнее: большие объемы или высококачественные данные?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Корреляция Спирмена $\\\\rho $ для моделей fastText на курируемом небольшом наборе данных (чистом) C1 значительно улучшает базовые показатели ($\\\\rho =0,354$ для Twi и 0,322 для Yorùbá) даже при небольшом наборе данных. Улучшение можно было бы оправдать только увеличением словарного запаса в Twi, но в случае с йоруба расширение происходит почти на половину размера словарного запаса. Мы обнаружили, что добавление некоторых зашумленных текстов (набор данных C2) немного улучшает корреляцию для языка тви, но не для языка йоруба. Язык Twi выигрывает от статей в Википедии, поскольку его включение удваивает словарный запас и уменьшает предвзятость модели к религиозным текстам. Однако для йоруба зашумленные тексты часто игнорируют диакритические знаки или тональные знаки, что увеличивает размер словарного запаса за счет увеличения двусмысленности. В результате корреляция слегка ухудшается. Можно было бы ожидать, что обучение с большим количеством данных улучшит качество встраивания, но на основе результатов, полученных с набором данных C3, мы обнаружили, что помогают только данные высокого качества. Добавление JW300 увеличивает словарный запас в обоих случаях, но если в Twi корпус смешивает диалекты и является шумным, то для Yorubá он очень чистый и с полными диакритическими знаками. Следовательно, лучшие вложения для Йоруба получаются при обучении с набором данных C3, тогда как для Twi лучшим вариантом является C2. В обоих случаях тщательно подобранные вложения улучшают корреляцию с человеческими суждениями в задаче сходства $\\\\Delta \\\\rho =+0,25$ или, что то же самое, за счёт приращения $\\\\rho $ на 170% (Twi) и 180% (Yorùbá ).']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Насколько модель улучшается за счет массивных данных и насколько за счет качества?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какие две архитектуры используются?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "151e7e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Массивные и тщательно подобранные встраивания слов для языков с ограниченными ресурсами. Дело Йоруба и Тви\n",
      "-------\n",
      "ABSTRACT: Успех нескольких архитектур в изучении семантических представлений из неаннотированного текста и доступность такого рода текстов в многоязычных онлайн-ресурсах, таких как Википедия, способствовали массовому и автоматическому созданию ресурсов для нескольких языков. Оценка таких ресурсов обычно проводится для языков с высокими ресурсами, где есть шведский стол из задач и наборов тестов для оценки. Для языков с низким уровнем ресурсов оценка более сложна и обычно игнорируется в надежде, что впечатляющая способность архитектур глубокого обучения изучать (многоязычные) представления в условиях с высокими ресурсами сохраняется и в условиях с низкими ресурсами. В этой статье мы концентрируемся на двух африканских языках, йоруб\\'а и тви, и сравниваем встраивания слов, полученные таким способом, с встраиваниями слов, полученными из тщательно подобранных корпусов и языково-зависимой обработки. Мы анализируем шум в общедоступных корпусах, собираем качественные и зашумленные данные для двух языков и количественно оцениваем улучшения, которые зависят не только от количества данных, но и от качества. Мы также используем различные архитектуры, которые изучают представления слов как по поверхностным формам, так и по символам, чтобы дополнительно использовать всю доступную информацию, которая оказалась важной для этих языков. Для оценки мы вручную переводим набор данных пар слов wordim-353 с английского на Yor\\`ub\\'a и Twi. В результате работы мы предоставляем корпуса, встраивания и тестовые наборы для обоих языков.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Что окажется важнее: большие объемы или высококачественные данные?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Корреляция Спирмена $\\\\rho $ для моделей fastText на курируемом небольшом наборе данных (чистом) C1 значительно улучшает базовые показатели ($\\\\rho =0,354$ для Twi и 0,322 для Yorùbá) даже при небольшом наборе данных. Улучшение можно было бы оправдать только увеличением словарного запаса в Twi, но в случае с йоруба расширение происходит почти на половину размера словарного запаса. Мы обнаружили, что добавление некоторых зашумленных текстов (набор данных C2) немного улучшает корреляцию для языка тви, но не для языка йоруба. Язык Twi выигрывает от статей в Википедии, поскольку его включение удваивает словарный запас и уменьшает предвзятость модели к религиозным текстам. Однако для йоруба зашумленные тексты часто игнорируют диакритические знаки или тональные знаки, что увеличивает размер словарного запаса за счет увеличения двусмысленности. В результате корреляция слегка ухудшается. Можно было бы ожидать, что обучение с большим количеством данных улучшит качество встраивания, но на основе результатов, полученных с набором данных C3, мы обнаружили, что помогают только данные высокого качества. Добавление JW300 увеличивает словарный запас в обоих случаях, но если в Twi корпус смешивает диалекты и является шумным, то для Yorubá он очень чистый и с полными диакритическими знаками. Следовательно, лучшие вложения для Йоруба получаются при обучении с набором данных C3, тогда как для Twi лучшим вариантом является C2. В обоих случаях тщательно подобранные вложения улучшают корреляцию с человеческими суждениями в задаче сходства $\\\\Delta \\\\rho =+0,25$ или, что то же самое, за счёт приращения $\\\\rho $ на 170% (Twi) и 180% (Yorùbá ).']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Насколько модель улучшается за счет массивных данных и насколько за счет качества?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какие две архитектуры используются?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c2a86883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Есть ли гендерная предвзятость и стереотипы в португальских словах?\n",
      "-------\n",
      "ABSTRACT: В этой работе мы предлагаем анализ наличия гендерных предубеждений, связанных с профессиями, в португальских словах. Целью данной работы является изучение гендерных последствий стереотипных профессий для женщин и мужчин в контексте португальского языка.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Эта статья ориентирована на европейский или бразильский португальский язык?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "\n",
      "-------\n",
      "QUESTION 2:\n",
      "На чем обучались встраиваниям слов?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какие вложения слов анализируются?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b38157e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Данные цитирования чешских высших судов\n",
      "-------\n",
      "ABSTRACT: В этой статье мы представляем данные о цитировании высших судов Чехии (Верховный суд, Высший административный суд и Конституционный суд). Этот набор данных был автоматически извлечен из корпуса текстов решений чешских судов – CzCDC 1.0. Мы получили данные о цитировании, построив конвейер обработки естественного языка для извлечения идентификаторов судебных решений. В состав конвейера вошли (i) модель сегментации документов и (ii) модель распознавания ссылок. Кроме того, набор данных был обработан вручную для получения высококачественных данных о цитировании в качестве основы для последующего качественного и количественного анализа. Набор данных будет доступен широкой публике.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Экспериментировали ли они с этим набором данных?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "\n",
      "-------\n",
      "QUESTION 2:\n",
      "Как измеряется качество цитирования?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "Насколько велик набор данных?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40201951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: LAXARY: надежная и объяснимая модель анализа Twitter для оценки посттравматического стрессового расстройства\n",
      "-------\n",
      "ABSTRACT: Психическое здоровье ветеранов является серьезной национальной проблемой, поскольку большое количество ветеранов возвращается с недавней войны в Ираке и продолжающегося военного присутствия в Афганистане. Хотя в существующих значительных работах изучалась оценка посттравматического стрессового расстройства (ПТСР) на основе постов в Твиттере с использованием методов машинного обучения «черный ящик», клиницисты не могут доверять этим основам из-за отсутствия клинической объяснимости. Чтобы завоевать доверие врачей, мы исследуем большой вопрос: могут ли сообщения в Твиттере предоставить достаточно информации для заполнения клинических опросов по оценке посттравматического стрессового расстройства, которым врачи традиционно доверяют? Чтобы ответить на поставленный выше вопрос, мы предлагаем модель LAXARY (объяснимый запрос на основе лингвистического анализа), новую модель объяснимого искусственного интеллекта (XAI) для обнаружения и представления оценки посттравматического стрессового расстройства пользователей Твиттера с использованием модифицированного анализа лингвистического запроса и подсчета слов (LIWC). . Во-первых, мы используем клинически проверенные инструменты опросов для сбора данных клинической оценки посттравматического стрессового расстройства от реальных пользователей Твиттера и разрабатываем лингвистический словарь посттравматического стрессового расстройства, используя результаты опросов по оценке посттравматического стрессового расстройства. Затем мы используем лингвистический словарь посттравматического стрессового расстройства вместе с моделью машинного обучения, чтобы заполнить инструменты опроса для определения статуса посттравматического стрессового расстройства и его интенсивности у соответствующих пользователей Твиттера. Наша экспериментальная оценка 210 клинически проверенных пользователей Твиттера-ветеранов обеспечивает многообещающую точность как классификации посттравматического стрессового расстройства, так и оценки его интенсивности. Мы также оцениваем надежность и достоверность разработанного нами Лингвистического словаря по посттравматическому стрессу.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Они оценивают только наборы данных на английском языке?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "\n",
      "-------\n",
      "QUESTION 2:\n",
      "Упоминают ли авторы какие-либо возможные затруднения в этом исследовании?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "Как устанавливается интенсивность ПТСР?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n",
      "QUESTION 4:\n",
      "Как LIWC включен в эту систему?\n",
      "-------\n",
      "ANSWER 4:\n",
      "\n",
      "-------\n",
      "EVIDENCE 4:\n",
      "\n",
      "-------\n",
      "QUESTION 5:\n",
      "Сколько пользователей Твиттера охвачено клинически проверенным опросом?\n",
      "-------\n",
      "ANSWER 5:\n",
      "\n",
      "-------\n",
      "EVIDENCE 5:\n",
      "\n",
      "-------\n",
      "QUESTION 6:\n",
      "Какие клинически проверенные инструменты опроса используются?\n",
      "-------\n",
      "ANSWER 6:\n",
      "\n",
      "-------\n",
      "EVIDENCE 6:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2aa7f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Комплексное распознавание именованных объектов на CORD-19 с дистанционным или слабым контролем\n",
      "-------\n",
      "ABSTRACT: Мы создали этот набор данных CORD-19-NER с комплексным распознаванием именованных объектов (NER) в корпусе набора данных открытых исследований COVID-19 (CORD-19) (13 марта 2020 г.). Этот набор данных CORD-19-NER охватывает 74 детальных именованных типа объектов. Он генерируется автоматически путем объединения результатов аннотаций из четырех источников: (1) предварительно обученная модель NER по 18 общим типам объектов из Spacy, (2) предварительно обученная модель NER по 18 типам биомедицинских объектов из SciSpacy, (3) база знаний Модель NER на основе (KB) для 127 типов биомедицинских объектов с нашим методом NER с дистанционным контролем и (4) модель NER на основе исходных данных для 8 новых типов объектов (в частности, связанных с исследованиями COVID-19) с нашим NER со слабым контролем метод. Мы надеемся, что этот набор данных поможет сообществу интеллектуального анализа текста создавать последующие приложения. Мы также надеемся, что этот набор данных может помочь в исследованиях COVID-19 как с биомедицинской, так и с социальной стороны.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Экспериментировали ли они с набором данных?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['На рисунке FigREF28 мы показываем несколько примеров результатов аннотирования в CORD-19-NER. Мы видим, что наши методы с дистанционным или слабо контролируемым контролем достигают высокого качества, распознавая новые типы сущностей, требуя всего лишь нескольких начальных примеров в качестве входных данных. Например, мы распознали «SARS-CoV-2» как тип «КОРОНАВИРУС», «летучие мыши» и «панголины» как тип «ДИКАЯ ЖИЗНЬ», а «силы Ван дер Ваальса» как тип «ФИЗИЧЕСКАЯ_НАУКА». Это результат аннотации NER. помочь последующим задачам анализа текста в обнаружении происхождения и физической природы вируса. Наши методы NER не зависят от предметной области и могут применяться к корпусу в разных областях. Кроме того, мы показываем еще один пример аннотации NER в New York Times с нашим система на рисунке FigREF29.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Каков размер этого набора данных?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Распознавание именованных объектов (NER) является фундаментальным шагом в разработке системы интеллектуального анализа текста для облегчения исследований COVID-19. Существует острая потребность в методах NER, которые могут быстро адаптироваться ко всем новым типам, связанным с COVID-19, без особых человеческих усилий для обучения аннотированию данных. Мы создали этот набор данных CORD-19-NER с подробной аннотацией именованных объектов в корпусе CORD-19 (13 марта 2020 г.). Этот набор данных охватывает 75 детализированных именованных типов объектов. CORD-19-NER генерируется автоматически путем объединения результатов аннотаций из четырех источников. В следующих разделах мы представим подробную информацию о построении набора данных CORD-19-NER. Мы также показываем некоторые результаты аннотаций NER в этом наборе данных.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Перечисляют ли они все присутствующие именованные типы сущностей?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['FLOAT SELECTED: Таблица 2: Примеры наиболее часто встречающихся объектов, аннотируемых в CORD-NER.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0f01dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: UniSent: универсальная адаптируемая лексика Sentiment Lexica для более чем 1000 языков\n",
      "-------\n",
      "ABSTRACT: В этой статье мы представляем UniSent — универсальную лексику настроений для 1000 языков, созданную с использованием словаря английских настроений и массового параллельного корпуса в области Библии. Насколько нам известно, UniSent на сегодняшний день является крупнейшим ресурсом по настроениям с точки зрения количества охваченных языков, включая многие языки с ограниченными ресурсами. Для создания UniSent мы предлагаем Adapted Sentiment Pivot, новый метод, который сочетает в себе проецирование аннотаций, расширение словарного запаса и неконтролируемую адаптацию предметной области. Мы оцениваем качество UniSent для македонского, чешского, немецкого, испанского и французского языков и показываем, что его качество сопоставимо с ресурсами настроений, созданными вручную или полувручную. Публикуя эту статью, мы выпускаем UniSent lexica, а также коды, связанные с Adapted Sentiment Pivot. метод.\n",
      "-------\n",
      "QUESTION 1:\n",
      "как измеряется качество?\n",
      "-------\n",
      "ANSWER 1:\n",
      "Точность и макро-F1 (усредненный F1 по положительным и отрицательным классам) используются в качестве меры качества.\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['FLOAT SELECTED: Таблица 1: Сравнение эффективности словаря, созданного вручную, с UniSent на чешском, немецком, французском, македонском и испанском языках. Мы сообщаем о точности и макро-F1 (усредненный F1 по положительным и отрицательным классам). Базовый уровень постоянно учитывает мнение большинства. Последние два столбца указывают производительность UniSent после взвешивания дрейфа.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "для скольких языков конкретно предназначена эта лексика?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "\n",
      "-------\n",
      "QUESTION 3:\n",
      "с какими источниками настроений они сравниваются?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec243afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Устранение неоднозначности смысла слова для 158 языков с использованием только встраивания слов\n",
      "-------\n",
      "ABSTRACT: Устранение неоднозначности значений слов в контексте легко для людей, но является серьезной проблемой для автоматических подходов. Для решения этой задачи были разработаны сложные контролируемые и основанные на знаниях модели. Однако (i) присущее Ципфу распределение контролируемых примеров обучения для данного слова и/или (ii) качество репрезентаций лингвистических знаний мотивируют разработку совершенно неконтролируемых и не требующих знаний подходов к устранению смысловой неоднозначности слов (WSD). Они особенно полезны для языков с ограниченными ресурсами, в которых нет ресурсов для построения контролируемых моделей и/или моделей, основанных на знаниях. В этой статье мы представляем метод, который принимает в качестве входных данных стандартную предварительно обученную модель встраивания слов и создает полноценный инвентарь смыслов слов, который можно использовать для устранения неоднозначности в контексте. Мы используем этот метод для создания коллекции смысловых инвентаризаций для 158 языков на основе исходных предварительно обученных встраиваний слов fastText, выполненных Grave et al. (2018), включив WSD на этих языках. Модели и система доступны онлайн.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Является ли метод, описанный в этой работе, методом, основанным на кластеризации?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['Задачу индукции смысла слова (WSI) можно рассматривать как неконтролируемую версию WSD. WSI нацелен на кластеризацию значений слов и не требует сопоставления каждого кластера с заранее определенным смыслом. Вместо этого инвентаризация значений слов автоматически создается из кластеров, рассматривая каждый кластер как одно значение слова. Подходы WSI делятся на три основные группы: кластеризация контекста, кластеризация словесной эго-сети и кластеризация синонимов (или заменителей).']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Как аннотируются/маркируются различные чувства?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['Набор данных состоит из набора многозначных слов: 20 существительных, 20 глаголов и 10 прилагательных и определяет от 20 до 100 контекстов на слово, всего 4664 контекста, взятых из Открытого американского национального корпуса. Учитывая набор контекстов многозначного слова, участникам конкурса пришлось разделить их на кластеры по смыслу слова. Контексты вручную помечаются смыслами целевых слов WordNet, на основе этой маркировки создается золотой стандарт кластеризации.']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Проводилась ли какая-либо внешняя оценка?\n",
      "-------\n",
      "ANSWER 3:\n",
      "\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['Сначала мы оцениваем наши преобразованные модели внедрения в задачах многоязычного лексического сходства и родства в качестве проверки работоспособности, чтобы убедиться, что процесс индукции смысла слова не повредил общей производительности встраивания. Затем мы проверяем смысловые встраивания в задаче WSD.']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5a9813b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Идентификация разговорного языка с использованием ConvNets\n",
      "-------\n",
      "ABSTRACT: Идентификация языка (LI) является важным первым шагом в некоторых системах обработки речи. С ростом числа голосовых помощников речевая LI стала широко исследуемой областью. Чтобы подойти к проблеме идентификации языков, мы можем принять либо неявный подход, при котором присутствует только речь языка, либо явный подход, при котором доступен текст с соответствующей транскрипцией. В данной статье основное внимание уделяется неявному подходу из-за отсутствия транскриптивных данных. В этой статье сравниваются существующие модели и предлагается новая модель языковой идентификации, основанная на внимании, которая использует изображения спектрограммы log-Mel в качестве входных данных. Мы также представляем эффективность необработанных сигналов как характеристик моделей нейронных сетей для задач LI. Для обучения и оценки моделей мы классифицировали шесть языков (английский, французский, немецкий, испанский, русский и итальянский) с точностью 95,4% и четыре языка (английский, французский, немецкий, испанский) с точностью 96,3%, полученные из набор данных VoxForge. Этот подход может быть расширен для включения большего количества языков.\n",
      "-------\n",
      "QUESTION 1:\n",
      "Использует ли модель как изображения спектрограмм, так и необработанные сигналы в качестве функций?\n",
      "-------\n",
      "ANSWER 1:\n",
      "\n",
      "-------\n",
      "EVIDENCE 1:\n",
      "['FLOAT SELECTED: Таблица 4: Результаты двух моделей и всех их вариаций.']\n",
      "-------\n",
      "QUESTION 2:\n",
      "Сравнивается ли производительность с базовой моделью?\n",
      "-------\n",
      "ANSWER 2:\n",
      "\n",
      "-------\n",
      "EVIDENCE 2:\n",
      "['В таблице TABREF1 мы суммируем количественные результаты вышеупомянутых предыдущих исследований. Он включает в себя основу модели, описание функций, классификацию языков и используемый набор данных, а также полученную точность. В таблице также приведены общие результаты предложенных нами моделей (вверху). Языки, используемые различными авторами вместе с их аббревиатурами: английский (En), испанский (Es), французский (Fr), немецкий (De), русский (Ru), итальянский (It), бенгальский (Ben), хинди (Hi). и Телегу (Тел.).']\n",
      "-------\n",
      "QUESTION 3:\n",
      "Какова точность, которую показывают современные методы?\n",
      "-------\n",
      "ANSWER 3:\n",
      "Ответ без содержания: (Таблица 1)\n",
      "Предыдущее состояние дел в том же наборе данных: ResNet50 89% (6 языков), SVM-HMM 70% (4 языка)\n",
      "-------\n",
      "EVIDENCE 3:\n",
      "['В таблице TABREF1 мы суммируем количественные результаты вышеупомянутых предыдущих исследований. Он включает в себя основу модели, описание функций, классификацию языков и используемый набор данных, а также полученную точность. В таблице также приведены общие результаты предложенных нами моделей (вверху). Языки, используемые различными авторами вместе с их аббревиатурами: английский (En), испанский (Es), французский (Fr), немецкий (De), русский (Ru), итальянский (It), бенгальский (Ben), хинди (Hi). и Телегу (Тел.).']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "get_qas(data, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a50691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
